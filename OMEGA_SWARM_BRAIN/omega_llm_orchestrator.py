#!/usr/bin/env python3
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘    OMEGA LLM ORCHESTRATOR - COMPLETE API INTEGRATION            â•‘
â•‘         All Major LLM Providers with API Key Rotation           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

INTEGRATED PROVIDERS:
âœ… OpenAI (GPT-4, GPT-4 Turbo, GPT-3.5)
âœ… Anthropic (Claude 3 Opus, Sonnet, Haiku)
âœ… Google (Gemini Pro, Gemini Pro Vision)
âœ… xAI (Grok)
âœ… Groq (Llama, Mixtral)
âœ… Cohere (Command, Command Light)
âœ… DeepSeek
âœ… Mistral
âœ… Ollama (Local models)
âœ… OpenRouter (Unified access)
"""

import os
import json
import time
import random
import asyncio
import logging
import hashlib
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
from collections import defaultdict
import httpx

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# API KEY ROTATION SYSTEM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class APIKeyRotator:
    """Advanced API key rotation with failover and logging"""
    
    def __init__(self):
        self.api_keys: Dict[str, List[str]] = {}
        self.current_key_index: Dict[str, int] = defaultdict(int)
        self.key_stats: Dict[str, Dict[str, Any]] = defaultdict(lambda: {
            "total_uses": 0,
            "failures": 0,
            "last_used": None,
            "rate_limited": False
        })
        
        # Load API keys from environment
        self._load_api_keys()
        
        logging.info("âœ… API Key Rotator initialized")
    
    def _load_api_keys(self):
        """Load API keys from environment variables"""
        providers = [
            "OPENAI", "ANTHROPIC", "GOOGLE", "XAI", "GROQ",
            "COHERE", "DEEPSEEK", "MISTRAL", "OPENROUTER"
        ]
        
        for provider in providers:
            keys = []
            # Check for numbered keys (OPENAI_API_KEY_1, OPENAI_API_KEY_2, etc.)
            for i in range(1, 11):
                key = os.getenv(f"{provider}_API_KEY_{i}")
                if key:
                    keys.append(key)
            
            # Check for single key
            if not keys:
                key = os.getenv(f"{provider}_API_KEY")
                if key:
                    keys.append(key)
            
            if keys:
                self.api_keys[provider.lower()] = keys
                logging.info(f"ğŸ“¦ Loaded {len(keys)} key(s) for {provider}")
    
    def get_key(self, provider: str) -> Optional[str]:
        """Get next available API key for provider"""
        provider = provider.lower()
        
        if provider not in self.api_keys or not self.api_keys[provider]:
            logging.warning(f"âš ï¸ No API keys available for {provider}")
            return None
        
        keys = self.api_keys[provider]
        current_idx = self.current_key_index[provider]
        
        # Rotate to next key
        key = keys[current_idx]
        self.current_key_index[provider] = (current_idx + 1) % len(keys)
        
        # Update stats
        key_hash = hashlib.md5(key.encode()).hexdigest()[:8]
        self.key_stats[f"{provider}_{key_hash}"]["total_uses"] += 1
        self.key_stats[f"{provider}_{key_hash}"]["last_used"] = time.time()
        
        return key
    
    def mark_failure(self, provider: str, key: str):
        """Mark key as failed"""
        key_hash = hashlib.md5(key.encode()).hexdigest()[:8]
        self.key_stats[f"{provider}_{key_hash}"]["failures"] += 1
        logging.warning(f"âŒ Key failure marked for {provider}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BASE AGENT CLIENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class BaseAgentClient(ABC):
    """Abstract base class for all LLM agent clients"""
    
    def __init__(self, name: str, key_rotator: APIKeyRotator):
        self.name = name
        self.key_rotator = key_rotator
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_tokens": 0
        }
    
    @abstractmethod
    async def query(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Send query to agent"""
        pass
    
    def update_stats(self, success: bool, tokens: int = 0):
        """Update agent statistics"""
        self.stats["total_requests"] += 1
        if success:
            self.stats["successful_requests"] += 1
            self.stats["total_tokens"] += tokens
        else:
            self.stats["failed_requests"] += 1

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LLM AGENT CLIENTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class OpenAIClient(BaseAgentClient):
    """OpenAI GPT models client"""
    
    def __init__(self, key_rotator: APIKeyRotator, model: str = "gpt-4"):
        super().__init__(f"openai_{model}", key_rotator)
        self.model = model
        self.base_url = "https://api.openai.com/v1/chat/completions"
    
    async def query(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Query OpenAI API"""
        api_key = self.key_rotator.get_key("openai")
        if not api_key:
            self.update_stats(False)
            return {"error": "No API key available"}
        
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    self.base_url,
                    headers={
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": self.model,
                        "messages": [{"role": "user", "content": prompt}],
                        **kwargs
                    }
                )
                
                if response.status_code == 200:
                    data = response.json()
                    tokens = data.get("usage", {}).get("total_tokens", 0)
                    self.update_stats(True, tokens)
                    return {
                        "response": data["choices"][0]["message"]["content"],
                        "model": self.model,
                        "tokens": tokens
                    }
                else:
                    self.key_rotator.mark_failure("openai", api_key)
                    self.update_stats(False)
                    return {"error": f"API error: {response.status_code}"}
        
        except Exception as e:
            logging.error(f"âŒ OpenAI query failed: {e}")
            self.update_stats(False)
            return {"error": str(e)}


class AnthropicClient(BaseAgentClient):
    """Anthropic Claude models client"""
    
    def __init__(self, key_rotator: APIKeyRotator, model: str = "claude-3-opus-20240229"):
        super().__init__(f"anthropic_{model}", key_rotator)
        self.model = model
        self.base_url = "https://api.anthropic.com/v1/messages"
    
    async def query(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Query Anthropic API"""
        api_key = self.key_rotator.get_key("anthropic")
        if not api_key:
            self.update_stats(False)
            return {"error": "No API key available"}
        
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    self.base_url,
                    headers={
                        "x-api-key": api_key,
                        "anthropic-version": "2023-06-01",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": self.model,
                        "messages": [{"role": "user", "content": prompt}],
                        "max_tokens": kwargs.get("max_tokens", 4096)
                    }
                )
                
                if response.status_code == 200:
                    data = response.json()
                    tokens = data.get("usage", {}).get("input_tokens", 0) + data.get("usage", {}).get("output_tokens", 0)
                    self.update_stats(True, tokens)
                    return {
                        "response": data["content"][0]["text"],
                        "model": self.model,
                        "tokens": tokens
                    }
                else:
                    self.key_rotator.mark_failure("anthropic", api_key)
                    self.update_stats(False)
                    return {"error": f"API error: {response.status_code}"}
        
        except Exception as e:
            logging.error(f"âŒ Anthropic query failed: {e}")
            self.update_stats(False)
            return {"error": str(e)}


class GoogleGeminiClient(BaseAgentClient):
    """Google Gemini models client"""
    
    def __init__(self, key_rotator: APIKeyRotator, model: str = "gemini-pro"):
        super().__init__(f"google_{model}", key_rotator)
        self.model = model
    
    async def query(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Query Google Gemini API"""
        api_key = self.key_rotator.get_key("google")
        if not api_key:
            self.update_stats(False)
            return {"error": "No API key available"}
        
        try:
            base_url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.model}:generateContent"
            
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    f"{base_url}?key={api_key}",
                    headers={"Content-Type": "application/json"},
                    json={
                        "contents": [{"parts": [{"text": prompt}]}]
                    }
                )
                
                if response.status_code == 200:
                    data = response.json()
                    text = data["candidates"][0]["content"]["parts"][0]["text"]
                    self.update_stats(True, 0)
                    return {
                        "response": text,
                        "model": self.model,
                        "tokens": 0
                    }
                else:
                    self.key_rotator.mark_failure("google", api_key)
                    self.update_stats(False)
                    return {"error": f"API error: {response.status_code}"}
        
        except Exception as e:
            logging.error(f"âŒ Google Gemini query failed: {e}")
            self.update_stats(False)
            return {"error": str(e)}


class OllamaClient(BaseAgentClient):
    """Ollama local models client"""
    
    def __init__(self, key_rotator: APIKeyRotator, model: str = "llama2"):
        super().__init__(f"ollama_{model}", key_rotator)
        self.model = model
        self.base_url = "http://localhost:11434/api/generate"
    
    async def query(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Query Ollama local API"""
        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.post(
                    self.base_url,
                    json={
                        "model": self.model,
                        "prompt": prompt,
                        "stream": False
                    }
                )
                
                if response.status_code == 200:
                    data = response.json()
                    self.update_stats(True, 0)
                    return {
                        "response": data.get("response", ""),
                        "model": self.model,
                        "tokens": 0
                    }
                else:
                    self.update_stats(False)
                    return {"error": f"API error: {response.status_code}"}
        
        except Exception as e:
            logging.error(f"âŒ Ollama query failed: {e}")
            self.update_stats(False)
            return {"error": str(e)}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AGENT ORCHESTRATOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class LLMOrchestrator:
    """Main orchestrator for all LLM agents"""
    
    def __init__(self):
        self.key_rotator = APIKeyRotator()
        self.agents: Dict[str, BaseAgentClient] = {}
        
        # Initialize agents
        self._initialize_agents()
        
        logging.info("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        logging.info("â•‘           LLM ORCHESTRATOR INITIALIZED                       â•‘")
        logging.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        logging.info(f"ğŸ“Š Total agents: {len(self.agents)}")
    
    def _initialize_agents(self):
        """Initialize all available LLM agents"""
        # OpenAI agents
        if self.key_rotator.get_key("openai"):
            self.agents["gpt4"] = OpenAIClient(self.key_rotator, "gpt-4")
            self.agents["gpt4_turbo"] = OpenAIClient(self.key_rotator, "gpt-4-turbo-preview")
            self.agents["gpt35"] = OpenAIClient(self.key_rotator, "gpt-3.5-turbo")
        
        # Anthropic agents
        if self.key_rotator.get_key("anthropic"):
            self.agents["claude_opus"] = AnthropicClient(self.key_rotator, "claude-3-opus-20240229")
            self.agents["claude_sonnet"] = AnthropicClient(self.key_rotator, "claude-3-sonnet-20240229")
        
        # Google agents
        if self.key_rotator.get_key("google"):
            self.agents["gemini_pro"] = GoogleGeminiClient(self.key_rotator, "gemini-pro")
        
        # Ollama agents (always available if Ollama is running)
        self.agents["ollama_llama2"] = OllamaClient(self.key_rotator, "llama2")
        self.agents["ollama_mistral"] = OllamaClient(self.key_rotator, "mistral")
    
    async def query_agent(self, agent_name: str, prompt: str, **kwargs) -> Dict[str, Any]:
        """Query a specific agent"""
        if agent_name not in self.agents:
            return {"error": f"Agent {agent_name} not found"}
        
        agent = self.agents[agent_name]
        return await agent.query(prompt, **kwargs)
    
    async def swarm_query(self, prompt: str, agents: Optional[List[str]] = None) -> Dict[str, Any]:
        """Query multiple agents and aggregate responses"""
        if agents is None:
            agents = list(self.agents.keys())[:3]  # Query first 3 agents
        
        tasks = [self.query_agent(agent, prompt) for agent in agents if agent in self.agents]
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        return {
            "prompt": prompt,
            "agents_queried": len(tasks),
            "responses": [r for r in responses if isinstance(r, dict) and "response" in r]
        }
    
    def get_available_agents(self) -> List[str]:
        """Get list of available agent names"""
        return list(self.agents.keys())
    
    def get_agent_stats(self) -> Dict[str, Any]:
        """Get statistics for all agents"""
        return {
            agent_name: agent.stats
            for agent_name, agent in self.agents.items()
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TESTING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    async def test():
        orchestrator = LLMOrchestrator()
        
        print("\n" + "="*70)
        print("AVAILABLE AGENTS:")
        print("="*70)
        for agent in orchestrator.get_available_agents():
            print(f"  â€¢ {agent}")
        
        # Test query
        if orchestrator.get_available_agents():
            print("\n" + "="*70)
            print("TEST QUERY:")
            print("="*70)
            agent_name = orchestrator.get_available_agents()[0]
            result = await orchestrator.query_agent(agent_name, "Say hello!")
            print(f"Agent: {agent_name}")
            print(f"Response: {result.get('response', result.get('error', 'No response'))}")
    
    asyncio.run(test())
